{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Anomalies in Images  \n",
    "\n",
    "Anomaly detection deals with the problem to find data items that do not follow the patterns of the majority of data.\n",
    "The task is to distinguish good and anomalous items. This can be in principal defined as a binary classification problem and as such be solved with supervised learning techniques. However, classes can be highly imbalanced.\n",
    "\n",
    "Imaging an industrial manufacturing processes, where millions of parts are produced every day, but 1 percent of the production may be defect. A supervised learning approach would clearly suffer from this imbalance. Autoencoders however are perfect for this situation, because they can be trained on normal parts. Once trained, they would well reconstruct normal parts, but would struggle to reconstruct anomalies. The larger the difference between autoencoder input and output, the more likely the input contains an anomaly.\n",
    "\n",
    "Autoencoders consist of two parts: encoder and decoder. It encodes input data and the goal is to reconstruct data such that the output is equal the input. The network is subject to constraints that forces the autoencoder to learn a compressed representation of the training set. It does this in an unsupervised manner and is therefore most suitable for problems related to anomaly detection. \n",
    "\n",
    "\n",
    "This notebook gives an example for an autoencoder trained on [UCSD Anomaly Detection Dataset](http://www.svcl.ucsd.edu/projects/anomaly/dataset.htm)\n",
    "\n",
    "Let's start by downloading and extracting the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from urllib import urlopen\n",
    "import tarfile\n",
    "import os\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from PIL import Image\n",
    "from scipy import signal\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "if not os.path.isfile(\"UCSD_Anomaly_Dataset.tar.gz\"):\n",
    "  response = urlopen(\"http://www.svcl.ucsd.edu/projects/anomaly/UCSD_Anomaly_Dataset.tar.gz\")\n",
    "  html = response.read()\n",
    "  tar = tarfile.open(\"UCSD_Anomaly_Dataset.tar.gz\")\n",
    "  tar.extractall()\n",
    "  tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Autoencoder (CAE)\n",
    "\n",
    "Let's define the network structure. The encoder consists of two convolutional and two MaxPooling layers. Encoder and Decoder are connected by a fully connected layer. The larger this bottleneck, the more information can be reconstructed. The decoder consists of two Upsampling layers and two Deconvolutions.\n",
    "\n",
    "![Autoencoder](network.png \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder(gluon.nn.HybridBlock):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvolutionalAutoencoder, self).__init__()\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.encoder = gluon.nn.HybridSequential()\n",
    "            with self.encoder.name_scope():\n",
    "                self.encoder.add(gluon.nn.Conv2D(32, 5, activation='relu'))\n",
    "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
    "                self.encoder.add(gluon.nn.Conv2D(32, 5, activation='relu'))\n",
    "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
    "                self.encoder.add(gluon.nn.Dense(2000))\n",
    "\n",
    "            self.decoder = gluon.nn.HybridSequential()\n",
    "            with self.decoder.name_scope():\n",
    "                self.decoder.add(gluon.nn.Dense(32*22*22, activation='relu'))\n",
    "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
    "                self.decoder.add(gluon.nn.Conv2DTranspose(32, 5, activation='relu'))\n",
    "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
    "                self.decoder.add(gluon.nn.Conv2DTranspose(1, kernel_size=5, activation='sigmoid'))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder[0](x)\n",
    "        x = x.reshape((-1,32,22,22))\n",
    "        x = self.decoder[1:](x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the Autoencoder for 30 epochs and with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "num_epochs = 30\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images from the folder `UCSDped1` have the format 158x238 pixels. They are rescaled to 100x100 and normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_transform(data):\n",
    "    data = data.transpose((2, 0, 1))\n",
    "    return (data.astype('float32') / 255)\n",
    "\n",
    "files = sorted(glob.glob('UCSD_Anomaly_Dataset.v1p2/UCSDped1/Train/*/*'))\n",
    "a = np.zeros((len(files),1,100,100))\n",
    "\n",
    "for idx, filename in enumerate(files):\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((100,100))\n",
    "    a[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "dataset = gluon.data.ArrayDataset(mx.nd.array(a, dtype=np.float32))\n",
    "dataloader = gluon.data.DataLoader(dataset, batch_size=batch_size, last_batch='rollover',shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize the network and define loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalAutoencoder()\n",
    "model.hybridize()\n",
    "model.collect_params().initialize(mx.init.Xavier('gaussian'), ctx=ctx)\n",
    "loss_function = gluon.loss.L2Loss()\n",
    "optimizer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 1e-4, 'wd': 1e-5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for image_batch in dataloader:\n",
    "        \n",
    "        image = image_batch.as_in_context(ctx)\n",
    "\n",
    "        with mx.autograd.record():\n",
    "            output = model(image_batch)\n",
    "            loss = loss_function(output, image_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step(image.shape[0])\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, mx.nd.mean(loss).asscalar()))\n",
    "\n",
    "model.save_parameters(\"autoencoder_ucsd.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Autoencoder is trained, we can use our test dataset, which contains some anomalies. We focus here on `Test024`, which is a video sequence with a golf cart that should be detected as anomaly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob.glob('UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test024/*'))\n",
    "\n",
    "a = np.zeros((len(files),1,100,100))\n",
    "\n",
    "for idx,filename in enumerate(files):\n",
    "    im = Image.open(filename)\n",
    "    im = im.resize((100,100))\n",
    "    a[idx,0,:,:] = np.array(im, dtype=np.float32)/255.0\n",
    "\n",
    "dataset = gluon.data.ArrayDataset(mx.nd.array(a, dtype=np.float32))\n",
    "dataloader = gluon.data.DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function that will plot input and output images and the differnce between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, output, diff, H, threshold, counter):\n",
    "    \n",
    "    fig, (ax0, ax1, ax2,ax3) = plt.subplots(ncols=4, figsize=(10, 5))\n",
    "    ax0.set_axis_off()\n",
    "    ax1.set_axis_off()\n",
    "    ax2.set_axis_off()\n",
    "    \n",
    "    ax0.set_title('input image')\n",
    "    ax1.set_title('reconstructed image')\n",
    "    ax2.set_title('diff ')\n",
    "    ax3.set_title('anomalies')\n",
    "    \n",
    "    ax0.imshow(img, cmap=plt.cm.gray, interpolation='nearest') \n",
    "    ax1.imshow(output, cmap=plt.cm.gray, interpolation='nearest')   \n",
    "    ax2.imshow(diff, cmap=plt.cm.viridis, vmin=0, vmax=255, interpolation='nearest')  \n",
    "    ax3.imshow(img, cmap=plt.cm.gray, interpolation='nearest')\n",
    "    \n",
    "    x,y = np.where(H > threshold)\n",
    "    ax3.scatter(y,x,color='red',s=0.1) \n",
    "\n",
    "    plt.axis('off')\n",
    "    \n",
    "    fig.savefig('images/' + str(counter) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate over the test images. We compute the difference between input and output and create a pixel map `H` with a 4x4 convolution kernel. If a pixel value in `H` is larger than 4 times 255 it will be marked as anomaly. The maximum value for each pixel in `H` is 4x4x255. We perform this step, so that pixels will be marked only when their neighboring pixels are also anomalous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 4*255\n",
    "counter = 0\n",
    "try:\n",
    "    os.mkdir(\"images\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for image in dataloader:\n",
    "    \n",
    "    counter = counter + 1\n",
    "    img = image.as_in_context(mx.cpu())\n",
    "\n",
    "    output = model(img)\n",
    "    output = output.transpose((0,2,3,1))\n",
    "    image = image.transpose((0,2,3,1))\n",
    "    output = output.asnumpy()*255\n",
    "    img = image.asnumpy()*255\n",
    "    diff = np.abs(output-img)\n",
    "    \n",
    "    tmp = diff[0,:,:,0]\n",
    "    H = signal.convolve2d(tmp, np.ones((4,4)), mode='same')\n",
    " \n",
    "    plot(img[0,:,:,0], output[0,:,:,0], diff[0,:,:,0], H, threshold, counter)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### An example output video (with Dense layer):\n",
    "<img src=\"autoencoder_dense.gif\" width=\"800\" height=\"790\">\n",
    "\n",
    "As we can see in the video, the golf cart is successfully identified as anomaly. The autoencoder has learned to reconstruct human beings well, but it struggles with objects that it has not seen during training.\n",
    "The dimension of the bottleneck layer will influence how much information is transmitted between encoder and decoder. If we set it too large or even remove it, then images will be reconstructed quite well. In the video below we removed the layer, so information flows from the second MaxPooling layer directly to the first Upsampling layer. \n",
    "\n",
    "##### Example Video (without Dense layer):\n",
    "<img src=\"autoencoder_no_dense.gif\" width=\"800\" height=\"790\">\n",
    "\n",
    "As we can see the network can reconstruct persons and other objects much better than the network with bottleneck layer. But it also becomes more challenging to detect anomalies.\n",
    "\n",
    "### Spatio-Temporal Stacked frame AutoEncoder  (STSAE)\n",
    "One problem of the standard CAE is that it does not take into account the temporal aspect of sequence of images. The paper [\"Learning Temporal Regularity in Video Sequences\"](https://arxiv.org/abs/1604.04574) describes an autoencoder that can also learn spatio-temporal structures in datasets. Instead of considering only one image at a time we consider now `n` images at a time. CAE takes the input in the form of `[batch_size, 1, width, height]`) and STSAE takes `[batch_size, n, width, height]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedAutoencoder(gluon.nn.HybridBlock):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.encoder = gluon.nn.HybridSequential()\n",
    "            with self.encoder.name_scope():\n",
    "                self.encoder.add(gluon.nn.Conv2D(512, kernel_size=11, activation='relu'))\n",
    "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
    "                self.encoder.add(gluon.nn.Conv2D(256, kernel_size=5, activation='relu'))\n",
    "                self.encoder.add(gluon.nn.MaxPool2D(2))\n",
    "                self.encoder.add(gluon.nn.Conv2D(128, kernel_size=3, activation='relu'))\n",
    "\n",
    "            self.decoder = gluon.nn.HybridSequential()\n",
    "            with self.decoder.name_scope():\n",
    "                self.decoder.add(gluon.nn.Conv2DTranspose(channels=256, kernel_size=3, activation='relu'))\n",
    "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
    "                self.decoder.add(gluon.nn.Conv2DTranspose(channels=512, kernel_size=5, activation='relu'))\n",
    "                self.decoder.add(gluon.nn.HybridLambda(lambda F, x: F.UpSampling(x, scale=2, sample_type='nearest')))\n",
    "                self.decoder.add(gluon.nn.Conv2DTranspose(channels=n, kernel_size=12, activation='tanh'))\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
